{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interact\n",
    "from copy import deepcopy\n",
    "from random import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ensemble_point(point, variables=['Temperature_height_above_ground_ens'], start=datetime.utcnow()-timedelta(hours=12), end=datetime.utcnow()+timedelta(hours=48)):\n",
    "    \"\"\"\n",
    "    Retrieves the latest (\"best\") ensemble forecast valid at a single point from the Unidata THREDDS server using\n",
    "    the Unidata siphon library.\n",
    "    \n",
    "    Requires:\n",
    "    point -> A tuple of (lat, lon) of the point we are trying to retrieve\n",
    "    variables -> A list of variables we want to retrieve.  Check this page for a full list:\n",
    "            http://thredds.ucar.edu/thredds/metadata/grib/NCEP/GEFS/Global_1p0deg_Ensemble/members/Best?metadata=variableMap\n",
    "    start -> A datetime object of the earliest time to look for an ensemble initialization,\n",
    "            default is current time minus 12 hours\n",
    "    end -> The last time for which we want ensemble forecast output.  Default is current time plus 48 hours.\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary with one item being the list of valid times in the data ('times') and the rest of the items\n",
    "    being numpy arrays of nTimes x nEnsmems for each variable requested\n",
    "        \n",
    "    \"\"\"\n",
    "    # Import the Siphon utilities \n",
    "    from siphon.catalog import TDSCatalog\n",
    "    from siphon.ncss import NCSS\n",
    "    \n",
    "    # In Siphon, we connect to a thredds catalog.  Here's the address for the GEFS\n",
    "    catalog = 'http://thredds.ucar.edu/thredds/catalog/grib/NCEP/GEFS/Global_1p0deg_Ensemble/members/catalog.xml' \n",
    "    best_model = TDSCatalog(catalog)\n",
    "    \n",
    "    # We select a specific dataset in this catalog, in this case the \"best\" (most recent) ensemble run \n",
    "    best_ds = list(best_model.datasets.values())[2]\n",
    "    ncss = NCSS(best_ds.access_urls['NetcdfSubset'])\n",
    "\n",
    "    \n",
    "    \n",
    "    # Here we format our subsetting query.  We specify the exact point we want,\n",
    "    # the time range, and the variables we are requesting.  We're also going\n",
    "    # to retrieve the data in a netcdf-like format\n",
    "    query = ncss.query()\n",
    "    query.lonlat_point(point[1], point[0])\n",
    "    query.time_range(start, end)\n",
    "    query.variables(*variables)\n",
    "    query.accept('netcdf')\n",
    "\n",
    "    # Actually get the data\n",
    "    data = ncss.get_data(query)\n",
    "    \n",
    "    # Format our output into a dictionary\n",
    "    output = {}\n",
    "    for v in variables:\n",
    "        # After the squeeze, this is a nTimes x nEns array\n",
    "        output[v] = np.squeeze(data.variables[v][:])\n",
    "        #print output[v].shape\n",
    "    # Also, add times\n",
    "    # The 'time' variable is hours since \"time_coverage_start\"\n",
    "    # Get this in datetime format\n",
    "    raw_hours = list(np.squeeze(data.variables['time'][:]))\n",
    "    init_time = datetime.strptime(str(data.time_coverage_start), '%Y-%m-%dT%H:%M:%SZ')\n",
    "    output['times'] = [init_time + timedelta(hours=int(x)) for x in raw_hours]\n",
    "    \n",
    "    # Return a dictionary\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This returns a dictionary of the ensemble forecast\n",
    "ensemble = get_ensemble_point((47.4489, -122.3094), ['Temperature_height_above_ground_ens'])\n",
    "\n",
    "# One observation value (in Kelvin) for each of the first\n",
    "# five valid times in the ensemble output\n",
    "obs = [290, 290, 290, 290, 290, 290, 290, 290, 290, 290]\n",
    "#obs = [278.7, 280.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enkf(obs, prior, obs_range=(1,2), ob_error=1.0, inflation=1.0):\n",
    "    \"\"\"\n",
    "    Updates a prior ensemble given a selection of obs.\n",
    "    \n",
    "    Currently assumes that there is only one state variable and each observation\n",
    "    corresponds with successive times in that variable, starting at the beginning\n",
    "    of the ensemble state.\n",
    "    \n",
    "    Requires:\n",
    "    obs -> A list of observation values, each corresponding to a successive time in the forecast\n",
    "            and starting at the first valid time.\n",
    "    prior -> A nTimes x nEnsMems array of the state variable\n",
    "    obs_range -> Tuple (start, end) of which subset of observations to assimilate.  \n",
    "                In the list of observations, will use the subset from (start:end)\n",
    "    ob_error -> The error variance to use for the observations in units^2\n",
    "    inflation -> A simple multiplicative inflation factor to inflate the background ensemble covariances.\n",
    "                Default is 1.0\n",
    "    \n",
    "    Returns:\n",
    "        A nTimes x nEnsMems array of the prior updated by the observations (the posterior)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Figure out the size of our state and ensemble members\n",
    "    Nstate, Nens = prior.shape\n",
    "    # Filter based on obs range\n",
    "    obs = obs[obs_range[0]-1:obs_range[-1]]\n",
    "    #print obs, obs_range\n",
    "    post = deepcopy(prior)\n",
    "    \n",
    "    # Compute prior and posterior mean and perturbations\n",
    "    prior_mean = np.mean(prior, axis=1)\n",
    "    post_mean = np.mean(post, axis=1)\n",
    "    prior_pert = prior - prior_mean[:,None]\n",
    "    post_pert = post - post_mean[:,None]\n",
    "    \n",
    "    # Inflate the ensemble?\n",
    "    prior_pert *= inflation\n",
    "    post_pert *= inflation\n",
    "    \n",
    "    # For now we assume that the indices of the obs we are\n",
    "    # assimilating match up with indices in the state array\n",
    "    # Randomize the order of the observations every time\n",
    "    obdexes = range(len(obs))\n",
    "    obzip = list(zip(obdexes, obs))\n",
    "    shuffle(obzip)\n",
    "    \n",
    "    # Serial assimilation (no localization here, so this should be ok...)\n",
    "    for obval in obzip:\n",
    "        obnum, ob = obval\n",
    "        #print obnum, ob, obs_range[0]\n",
    "        ob_index = obs_range[0] + obnum -1\n",
    "        prior_mean = post_mean\n",
    "        prior_pert = post_pert\n",
    "        # Build H\n",
    "        H = np.zeros(Nstate)\n",
    "        H[ob_index] = 1.0\n",
    "        #print \"H:\", H\n",
    "        # Get estimate of ob (ye or HXb)\n",
    "        ye = np.dot(H, np.add(prior_pert, prior_mean[:,None]))\n",
    "        # Ensemble mean of ye\n",
    "        ye_mean = np.mean(ye)\n",
    "        # And variance in Ye\n",
    "        ye_variance = np.var(ye - ye_mean)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # Compute innovation (y-HXb)\n",
    "        innov = ob - ye_mean\n",
    "        #print \"Obnum:\", obnum, \"  Innov:\", innov,\n",
    "        #print \" Obval:\", ob, \"  ye:\", ye_mean\n",
    "        # Now the numerator of the Kalman gain--covariance between\n",
    "        # ensemble state and the ensemble estimate of the ob\n",
    "        kcov = np.dot(prior_pert, ye) / (Nens-1)\n",
    "              \n",
    "        # Compute the Kalman gain\n",
    "        K = np.divide(kcov, (ye_variance + ob_error))\n",
    "        #print K\n",
    "        \n",
    "        # Now update the mean -> x_post = x_prior + K * innovation\n",
    "        post_mean = prior_mean + np.multiply(K, innov)\n",
    "        \n",
    "        # Compute the square-root factor to account for sampling error\n",
    "        beta = 1.0 / (1.0 + np.sqrt(ob_error/(ye_variance + ob_error)))\n",
    "        \n",
    "        # Now update the perturbation\n",
    "        #print K.shape\n",
    "        #print ye.shape\n",
    "        #print prior_pert.shape\n",
    "        post_pert = prior_pert - np.dot((beta * K)[:,None], (ye-ye_mean)[None, :])\n",
    "\n",
    "    # Return the full posterior state (mean + pert)\n",
    "    return post_pert + post_mean[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assimilation_viewer(obs_range, ob_error, inflation, show_inflated):\n",
    "    # On calling the function, do the assimilation with the specified parameters\n",
    "    # Grab the prior state from the dictionary\n",
    "    prior = ensemble['Temperature_height_above_ground_ens']\n",
    "    prior_mean = np.mean(prior, axis=1)\n",
    "    prior_pert = prior - prior_mean[:, None]\n",
    "    \n",
    "    post = enkf(obs, prior, obs_range=obs_range, ob_error=ob_error, inflation=inflation)\n",
    "    post_mean = np.mean(post, axis=1)\n",
    "    \n",
    "    # Figure out if we're plotting inflated prior or not\n",
    "    if show_inflated:\n",
    "        prior_pert *= inflation\n",
    "        prior = prior_pert + prior_mean[:,None]\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12,10))\n",
    "    # Top panel will be a \"spaghetti plot\" of the prior and posterior ensemble trajectories\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    ax.plot(ensemble['times'], prior, c='LightSlateGrey', alpha=0.3)\n",
    "    ax.plot(ensemble['times'], post, c='Tomato', alpha=0.3)\n",
    "    ax.plot(ensemble['times'], prior_mean, c='LightSlateGrey', alpha=1.0, lw=2)\n",
    "    ax.plot(ensemble['times'], post_mean, c='Tomato', alpha=1.0, lw=2)\n",
    "    # Also, plot the observations we assimilated (Subsetting if obs_range has been changed)\n",
    "    ax.scatter(ensemble['times'][obs_range[0]-1:obs_range[-1]], obs[obs_range[0]-1:obs_range[-1]], c='k', s=60)\n",
    "    # Various titles, labels and prettifications...\n",
    "    ax.set_title('EFA Adjustment of Temperature Trajectory', fontsize=14)\n",
    "    ax.set_ylabel('Temperature [K]', fontsize=12)\n",
    "    ax.set_xlabel('Valid Time', fontsize=12)\n",
    "    ax.set_xlim((matplotlib.dates.date2num(ensemble['times'][0]), matplotlib.dates.date2num(ensemble['times'][-1])))\n",
    "    ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%d/%HZ'))\n",
    "    ax.grid()\n",
    "    \n",
    "    # Plot the ensemble prior and posterior variance\n",
    "    ax2 = plt.subplot(2,1,2)   \n",
    "    prior_var = np.var(prior - np.mean(prior,axis=1)[:,None], axis=1)\n",
    "    post_var = np.var(post - np.mean(post,axis=1)[:,None], axis=1)\n",
    "    ax2.plot(ensemble['times'], prior_var, lw=2, c='LightSlateGrey', label='Prior')\n",
    "    ax2.plot(ensemble['times'], post_var, lw=2, c='Tomato', label='Post')\n",
    "    # Remind us of the inflation\n",
    "    ax2.text(0.14,0.93,'Inflation: {:2.1f}'.format(inflation), fontsize=14, transform=ax2.transAxes, ha='left', va='center')\n",
    "    # More prettifications...\n",
    "    ax2.set_xlabel('Valid Time', fontsize=12)\n",
    "    ax2.set_xlim((matplotlib.dates.date2num(ensemble['times'][0]), matplotlib.dates.date2num(ensemble['times'][-1])))\n",
    "    ax2.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%d/%HZ'))\n",
    "    ax2.set_ylabel('Ens. Variance [K$^{2}$]', fontsize=12)\n",
    "    ax2.legend(loc=0)  \n",
    "    ax2.grid()\n",
    "    \n",
    "# This uses iPython widgets to build sliders for determining what to assimilate\n",
    "obs_slider = widgets.IntRangeSlider(min=1, max=len(obs), step=1, value=(1, len(obs)), description='Num. Obs. Assimilated')\n",
    "error_slider = widgets.FloatSlider(value=1.0, min=0.25, max=2.0, step=0.25, description='Obs. Error [K$^{2}$]')\n",
    "inflation_slider = widgets.FloatSlider(value=1.0, min=1.0, max=3.0, step=0.5, description='Inflation Factor')\n",
    "show_inflated_prior = widgets.Checkbox(description=\"Show inflated prior\", value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8300db4684b46edab615c2f4203d17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = widgets.interactive(assimilation_viewer, obs_range=obs_slider, ob_error=error_slider, inflation=inflation_slider, show_inflated=show_inflated_prior)  \n",
    "display(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
