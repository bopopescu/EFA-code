{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Forecast Adjustment Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luke Madaus, University of Washington, January 2016\n",
    "\n",
    "This iPython notebook demonstrates the Ensemble Forecast Adjustment technique (Madaus and Hakim 2015; QJRMS) for updating ensemble forecast trajectories with assimilated observations. Here we use a sample of the GEFS ensemble forecast of surface temperature with dummy observations to show how this technique works in an interactive way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll start by importing a variety of libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ipywidgets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cf9c96d8fe9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named ipywidgets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interact\n",
    "from copy import deepcopy\n",
    "from random import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring background information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to get an ensemble forecast we want to update.  Here we're using the Unidata Siphon library (https://github.com/Unidata/siphon; easily installed using \"pip install siphon\") to download the latest GFS Ensemble forecast (GEFS) for a single point.  The function below does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ensemble_point(point, variables=['Temperature_height_above_ground_ens'], start=datetime.utcnow()-timedelta(hours=12), end=datetime.utcnow()+timedelta(hours=48)):\n",
    "    \"\"\"\n",
    "    Retrieves the latest (\"best\") ensemble forecast valid at a single point from the Unidata THREDDS server using\n",
    "    the Unidata siphon library.\n",
    "    \n",
    "    Requires:\n",
    "    point -> A tuple of (lat, lon) of the point we are trying to retrieve\n",
    "    variables -> A list of variables we want to retrieve.  Check this page for a full list:\n",
    "            http://thredds.ucar.edu/thredds/metadata/grib/NCEP/GEFS/Global_1p0deg_Ensemble/members/Best?metadata=variableMap\n",
    "    start -> A datetime object of the earliest time to look for an ensemble initialization,\n",
    "            default is current time minus 12 hours\n",
    "    end -> The last time for which we want ensemble forecast output.  Default is current time plus 48 hours.\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary with one item being the list of valid times in the data ('times') and the rest of the items\n",
    "    being numpy arrays of nTimes x nEnsmems for each variable requested\n",
    "        \n",
    "    \"\"\"\n",
    "    # Import the Siphon utilities \n",
    "    from siphon.catalog import TDSCatalog\n",
    "    from siphon.ncss import NCSS\n",
    "    \n",
    "    # In Siphon, we connect to a thredds catalog.  Here's the address for the GEFS\n",
    "    catalog = 'http://thredds.ucar.edu/thredds/catalog/grib/NCEP/GEFS/Global_1p0deg_Ensemble/members/catalog.xml' \n",
    "    best_model = TDSCatalog(catalog)\n",
    "    \n",
    "    # We select a specific dataset in this catalog, in this case the \"best\" (most recent) ensemble run \n",
    "    best_ds = list(best_model.datasets.values())[2]\n",
    "    ncss = NCSS(best_ds.access_urls['NetcdfSubset'])\n",
    "\n",
    "    \n",
    "    \n",
    "    # Here we format our subsetting query.  We specify the exact point we want,\n",
    "    # the time range, and the variables we are requesting.  We're also going\n",
    "    # to retrieve the data in a netcdf-like format\n",
    "    query = ncss.query()\n",
    "    query.lonlat_point(point[1], point[0])\n",
    "    query.time_range(start, end)\n",
    "    query.variables(*variables)\n",
    "    query.accept('netcdf')\n",
    "\n",
    "    # Actually get the data\n",
    "    data = ncss.get_data(query)\n",
    "    \n",
    "    # Format our output into a dictionary\n",
    "    output = {}\n",
    "    for v in variables:\n",
    "        # After the squeeze, this is a nTimes x nEns array\n",
    "        output[v] = np.squeeze(data.variables[v][:])\n",
    "        #print output[v].shape\n",
    "    # Also, add times\n",
    "    # The 'time' variable is hours since \"time_coverage_start\"\n",
    "    # Get this in datetime format\n",
    "    raw_hours = list(np.squeeze(data.variables['time'][:]))\n",
    "    init_time = datetime.strptime(str(data.time_coverage_start), '%Y-%m-%dT%H:%M:%SZ')\n",
    "    output['times'] = [init_time + timedelta(hours=int(x)) for x in raw_hours]\n",
    "    \n",
    "    # Return a dictionary\n",
    "    return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the above function to request the ensemble forecast of surface temperature ('Temperature_height_above_ground_ens') for a point (here, Sea-Tac airport).  For now, we're also going to set some dummy observations that correspond to the first several valid times in the ensemble output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This returns a dictionary of the ensemble forecast\n",
    "ensemble = get_ensemble_point((47.4489, -122.3094), ['Temperature_height_above_ground_ens'])\n",
    "\n",
    "# One observation value (in Kelvin) for each of the first\n",
    "# five valid times in the ensemble output\n",
    "obs = [275., 275., 275.0, 275.0, 276.0]\n",
    "#obs = [278.7, 280.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Assimilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the background ensemble and observations, so now we can try assimilating them.  Below we define a function called \"enkf\" that implments an ensemble square-root filter version of the Kalman filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enkf(obs, prior, obs_range=(1,2), ob_error=1.0, inflation=1.0):\n",
    "    \"\"\"\n",
    "    Updates a prior ensemble given a selection of obs.\n",
    "    \n",
    "    Currently assumes that there is only one state variable and each observation\n",
    "    corresponds with successive times in that variable, starting at the beginning\n",
    "    of the ensemble state.\n",
    "    \n",
    "    Requires:\n",
    "    obs -> A list of observation values, each corresponding to a successive time in the forecast\n",
    "            and starting at the first valid time.\n",
    "    prior -> A nTimes x nEnsMems array of the state variable\n",
    "    obs_range -> Tuple (start, end) of which subset of observations to assimilate.  \n",
    "                In the list of observations, will use the subset from (start:end)\n",
    "    ob_error -> The error variance to use for the observations in units^2\n",
    "    inflation -> A simple multiplicative inflation factor to inflate the background ensemble covariances.\n",
    "                Default is 1.0\n",
    "    \n",
    "    Returns:\n",
    "        A nTimes x nEnsMems array of the prior updated by the observations (the posterior)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Figure out the size of our state and ensemble members\n",
    "    Nstate, Nens = prior.shape\n",
    "    # Filter based on obs range\n",
    "    obs = obs[obs_range[0]-1:obs_range[-1]]\n",
    "    #print obs, obs_range\n",
    "    post = deepcopy(prior)\n",
    "    \n",
    "    # Compute prior and posterior mean and perturbations\n",
    "    prior_mean = np.mean(prior, axis=1)\n",
    "    post_mean = np.mean(post, axis=1)\n",
    "    prior_pert = prior - prior_mean[:,None]\n",
    "    post_pert = post - post_mean[:,None]\n",
    "    \n",
    "    # Inflate the ensemble?\n",
    "    prior_pert *= inflation\n",
    "    post_pert *= inflation\n",
    "    \n",
    "    # For now we assume that the indices of the obs we are\n",
    "    # assimilating match up with indices in the state array\n",
    "    # Randomize the order of the observations every time\n",
    "    obdexes = range(len(obs))\n",
    "    obzip = list(zip(obdexes, obs))\n",
    "    shuffle(obzip)\n",
    "    \n",
    "    # Serial assimilation (no localization here, so this should be ok...)\n",
    "    for obval in obzip:\n",
    "        obnum, ob = obval\n",
    "        #print obnum, ob, obs_range[0]\n",
    "        ob_index = obs_range[0] + obnum -1\n",
    "        prior_mean = post_mean\n",
    "        prior_pert = post_pert\n",
    "        # Build H\n",
    "        H = np.zeros(Nstate)\n",
    "        H[ob_index] = 1.0\n",
    "        #print \"H:\", H\n",
    "        # Get estimate of ob (ye or HXb)\n",
    "        ye = np.dot(H, np.add(prior_pert, prior_mean[:,None]))\n",
    "        # Ensemble mean of ye\n",
    "        ye_mean = np.mean(ye)\n",
    "        # And variance in Ye\n",
    "        ye_variance = np.var(ye - ye_mean)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # Compute innovation (y-HXb)\n",
    "        innov = ob - ye_mean\n",
    "        #print \"Obnum:\", obnum, \"  Innov:\", innov,\n",
    "        #print \" Obval:\", ob, \"  ye:\", ye_mean\n",
    "        # Now the numerator of the Kalman gain--covariance between\n",
    "        # ensemble state and the ensemble estimate of the ob\n",
    "        kcov = np.dot(prior_pert, ye) / (Nens-1)\n",
    "              \n",
    "        # Compute the Kalman gain\n",
    "        K = np.divide(kcov, (ye_variance + ob_error))\n",
    "        #print K\n",
    "        \n",
    "        # Now update the mean -> x_post = x_prior + K * innovation\n",
    "        post_mean = prior_mean + np.multiply(K, innov)\n",
    "        \n",
    "        # Compute the square-root factor to account for sampling error\n",
    "        beta = 1.0 / (1.0 + np.sqrt(ob_error/(ye_variance + ob_error)))\n",
    "        \n",
    "        # Now update the perturbation\n",
    "        #print K.shape\n",
    "        #print ye.shape\n",
    "        #print prior_pert.shape\n",
    "        post_pert = prior_pert - np.dot((beta * K)[:,None], (ye-ye_mean)[None, :])\n",
    "\n",
    "    # Return the full posterior state (mean + pert)\n",
    "    return post_pert + post_mean[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below builds a matplotlib plot to show the ensemble state before and after assimilation, as well as the ensemble variance.  It uses iPython \"widgets\" to allow various parameters to be changed, namely the number of observations assimilated, the observation error variance and the inflation factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assimilation_viewer(obs_range, ob_error, inflation, show_inflated):\n",
    "    # On calling the function, do the assimilation with the specified parameters\n",
    "    # Grab the prior state from the dictionary\n",
    "    prior = ensemble['Temperature_height_above_ground_ens']\n",
    "    prior_mean = np.mean(prior, axis=1)\n",
    "    prior_pert = prior - prior_mean[:, None]\n",
    "    \n",
    "    post = enkf(obs, prior, obs_range=obs_range, ob_error=ob_error, inflation=inflation)\n",
    "    post_mean = np.mean(post, axis=1)\n",
    "    \n",
    "    # Figure out if we're plotting inflated prior or not\n",
    "    if show_inflated:\n",
    "        prior_pert *= inflation\n",
    "        prior = prior_pert + prior_mean[:,None]\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12,10))\n",
    "    # Top panel will be a \"spaghetti plot\" of the prior and posterior ensemble trajectories\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    ax.plot(ensemble['times'], prior, c='LightSlateGrey', alpha=0.3)\n",
    "    ax.plot(ensemble['times'], post, c='Tomato', alpha=0.3)\n",
    "    ax.plot(ensemble['times'], prior_mean, c='LightSlateGrey', alpha=1.0, lw=2)\n",
    "    ax.plot(ensemble['times'], post_mean, c='Tomato', alpha=1.0, lw=2)\n",
    "    # Also, plot the observations we assimilated (Subsetting if obs_range has been changed)\n",
    "    ax.scatter(ensemble['times'][obs_range[0]-1:obs_range[-1]], obs[obs_range[0]-1:obs_range[-1]], c='k', s=60)\n",
    "    # Various titles, labels and prettifications...\n",
    "    ax.set_title('EFA Adjustment of Temperature Trajectory', fontsize=14)\n",
    "    ax.set_ylabel('Temperature [K]', fontsize=12)\n",
    "    ax.set_xlabel('Valid Time', fontsize=12)\n",
    "    ax.set_xlim((matplotlib.dates.date2num(ensemble['times'][0]), matplotlib.dates.date2num(ensemble['times'][-1])))\n",
    "    ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%d/%HZ'))\n",
    "    ax.grid()\n",
    "    \n",
    "    # Plot the ensemble prior and posterior variance\n",
    "    ax2 = plt.subplot(2,1,2)   \n",
    "    prior_var = np.var(prior - np.mean(prior,axis=1)[:,None], axis=1)\n",
    "    post_var = np.var(post - np.mean(post,axis=1)[:,None], axis=1)\n",
    "    ax2.plot(ensemble['times'], prior_var, lw=2, c='LightSlateGrey', label='Prior')\n",
    "    ax2.plot(ensemble['times'], post_var, lw=2, c='Tomato', label='Post')\n",
    "    # Remind us of the inflation\n",
    "    ax2.text(0.14,0.93,'Inflation: {:2.1f}'.format(inflation), fontsize=14, transform=ax2.transAxes, ha='left', va='center')\n",
    "    # More prettifications...\n",
    "    ax2.set_xlabel('Valid Time', fontsize=12)\n",
    "    ax2.set_xlim((matplotlib.dates.date2num(ensemble['times'][0]), matplotlib.dates.date2num(ensemble['times'][-1])))\n",
    "    ax2.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%d/%HZ'))\n",
    "    ax2.set_ylabel('Ens. Variance [K$^{2}$]', fontsize=12)\n",
    "    ax2.legend(loc=0)  \n",
    "    ax2.grid()\n",
    "    \n",
    "# This uses iPython widgets to build sliders for determining what to assimilate\n",
    "obs_slider = widgets.IntRangeSlider(min=1, max=len(obs), step=1, value=(1, len(obs)), description='Num. Obs. Assimilated')\n",
    "error_slider = widgets.FloatSlider(value=1.0, min=0.25, max=2.0, step=0.25, description='Obs. Error [K$^{2}$]')\n",
    "inflation_slider = widgets.FloatSlider(value=1.0, min=1.0, max=3.0, step=0.5, description='Inflation Factor')\n",
    "show_inflated_prior = widgets.Checkbox(description=\"Show inflated prior\", value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the image generation function built and the sliders defined, we can display our interactive image.  \n",
    "\n",
    "Try experimenting with decreasing the observation error to see how that places more weight on the observations.  Or, similarly, increase the inflation factor to weight the observations more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'widgets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bc35bf912132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massimilation_viewer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_slider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mob_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_slider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minflation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minflation_slider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_inflated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_inflated_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'widgets' is not defined"
     ]
    }
   ],
   "source": [
    "w = widgets.interactive(assimilation_viewer, obs_range=obs_slider, ob_error=error_slider, inflation=inflation_slider, show_inflated=show_inflated_prior)  \n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
